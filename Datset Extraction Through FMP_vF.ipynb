{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4c0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "\n",
    "# I acknowledge the use of AI tools in debugging and writing the code\n",
    "\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed8d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import certifi\n",
    "import json\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Function to fetch and parse JSON data from a URL\n",
    "def get_jsonparsed_data(url):\n",
    "    response = urlopen(url, cafile=certifi.where())\n",
    "    data = response.read().decode(\"utf-8\")\n",
    "    return json.loads(data)\n",
    "\n",
    "# Function to get the S&P 500 tickers list\n",
    "def get_sp500_tickers():\n",
    "    sp500_url = \"https://financialmodelingprep.com/api/v3/api_key\"\n",
    "    tickers_data = get_jsonparsed_data(sp500_url)\n",
    "    return [\"NIO\"]\n",
    "#     return [item['symbol'] for item in tickers_data]  \n",
    "\n",
    "# Function to fetch data for a specific ticker, year, and quarter\n",
    "def fetch_data(ticker, year, quarter, base_url, apikey):\n",
    "    url = f\"{base_url}{ticker}?year={year}&quarter={quarter}&apikey={apikey}\"\n",
    "    try:\n",
    "        data = get_jsonparsed_data(url)\n",
    "        return [\n",
    "            {\n",
    "                \"ticker\": ticker,\n",
    "                \"year\": year,\n",
    "                \"quarter\": quarter,\n",
    "                \"date\": transcript.get(\"date\"),\n",
    "                \"content\": transcript.get(\"content\")\n",
    "            }\n",
    "            for transcript in data\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker} in {year} Q{quarter}: {e}\")\n",
    "        return []\n",
    "\n",
    "    \n",
    "\n",
    "# Main function to handle parallel API requests\n",
    "def main(years):\n",
    "    # Base URL for the earning call transcripts API\n",
    "    base_url = \"https://financialmodelingprep.com/api/v3/earning_call_transcript/\"\n",
    "    apikey = \"api_key\"\n",
    "\n",
    "#     # Define the range of years and quarters\n",
    "#     years = [2024, 2025]\n",
    "#              #2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025]\n",
    "    quarters = [1, 2, 3, 4]\n",
    "\n",
    "    # Get the list of all S&P 500 tickers\n",
    "    tickers = get_sp500_tickers()\n",
    "\n",
    "    # List to store all data\n",
    "    all_data = []\n",
    "    i = 0\n",
    "    # Use ThreadPoolExecutor for parallel requests\n",
    "    with ThreadPoolExecutor(max_workers=15) as executor:\n",
    "        futures = []\n",
    "        for ticker in tickers:\n",
    "            for year in years:\n",
    "                for quarter in quarters:\n",
    "                    i+=1\n",
    "                    if (i + 1) % 10 == 0:  # Pause for 1 second every 15 transcripts\n",
    "                        time.sleep(1)\n",
    "                        print(i)\n",
    "                    futures.append(executor.submit(fetch_data, ticker, year, quarter, base_url, apikey))\n",
    "\n",
    "        # Collect results and pause every 15 transcripts\n",
    "        for i, future in enumerate(futures):\n",
    "            all_data.extend(future.result())\n",
    "\n",
    "\n",
    "    # Convert the list to a DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    return df\n",
    "\n",
    "# Run the main function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043c8ef6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m2/ny_3r2zn14z8qxzlqbt2q1dh0000gn/T/ipykernel_19708/2526519687.py:10: DeprecationWarning: cafile, capath and cadefault are deprecated, use a custom context instead.\n",
      "  response = urlopen(url, cafile=certifi.where())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "19\n",
      "29\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "years = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025]\n",
    "df_NIO = main(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05ea6d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ticker', 'year', 'quarter', 'date', 'content'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NIO.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c609c9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 36\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#     print(row['content'][:500] + '...')  # printing first 500 chars for brevity\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Percentage calculation\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m percentage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_NIO\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_NIO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mafter_date\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpercentage\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% of transcripts after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mafter_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mention \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# # Ensure the date column is datetime\n",
    "# df_NIO['date'] = pd.to_datetime(df_NIO['date'])\n",
    "\n",
    "\n",
    "# # Filter df_2026 for these tickers\n",
    "# # df_2026 = df_2026[df_2026['ticker'].isin(peer_tickers)]\n",
    "# # Function to analyze keyword mentions\n",
    "# def transcripts_with_keyword(df, keyword, after_date):\n",
    "#     filtered_df = df[df['date'] > after_date].copy()\n",
    "\n",
    "#     # Count occurrences of the keyword (case-insensitive)\n",
    "#     filtered_df['keyword_count'] = filtered_df['content'].str.count(re.escape(keyword), flags=re.IGNORECASE)\n",
    "\n",
    "#     # Filter transcripts where keyword is mentioned at least once\n",
    "#     result_df = filtered_df[filtered_df['keyword_count'] > 0]\n",
    "\n",
    "#     return result_df[['ticker', 'date', 'keyword_count', 'content']]\n",
    "\n",
    "\n",
    "# # Example usage (easy to change keyword and date)\n",
    "# keyword = 'tariff'\n",
    "# after_date = '2025-01-01'\n",
    "\n",
    "# results = transcripts_with_keyword(df_NIO, keyword, after_date)\n",
    "\n",
    "# # Display results\n",
    "# for idx, row in results.iterrows():\n",
    "#     print(f\"\\nTicker: {row['ticker']} | Date: {row['date'].date()} | '{keyword}' mentioned {row['keyword_count']} times\")\n",
    "#     print(\"-\" * 80)\n",
    "# #     print(row['content'][:500] + '...')  # printing first 500 chars for brevity\n",
    "\n",
    "# # Percentage calculation\n",
    "# percentage = len(results) / len(df_NIO[df_NIO['date'] > after_date]) * 100\n",
    "# print(f\"\\n{percentage:.2f}% of transcripts after {after_date} mention '{keyword}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d667912a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ticker  year  quarter                date  \\\n",
      "8      WDAY  2024        1 2023-05-25 16:30:00   \n",
      "9      WDAY  2024        2 2023-08-24 16:30:00   \n",
      "10     WDAY  2024        3 2023-11-28 20:25:11   \n",
      "19     DELL  2024        1 2023-06-01 16:30:00   \n",
      "20     DELL  2024        2 2023-08-31 16:30:00   \n",
      "...     ...   ...      ...                 ...   \n",
      "1927     DE  2024        1 2024-02-15 10:00:00   \n",
      "1962    GIS  2024        1 2023-09-20 09:00:00   \n",
      "1963    GIS  2024        2 2023-12-20 09:00:00   \n",
      "2046     PG  2024        1 2023-10-18 08:30:00   \n",
      "2047     PG  2024        2 2024-01-23 08:30:00   \n",
      "\n",
      "                                                content  \n",
      "8     Operator: Welcome to Workday's First Quarter F...  \n",
      "9     Operator: Welcome to Workday's Fiscal 2024 Sec...  \n",
      "10    Operator: Welcome to Workday's Fiscal 2024 Thi...  \n",
      "19    Operator: Good afternoon, and welcome to the f...  \n",
      "20    Operator: Good afternoon, and welcome to the F...  \n",
      "...                                                 ...  \n",
      "1927  Operator: Good morning, and welcome to Deere &...  \n",
      "1962  Operator: Greetings, and welcome to the Genera...  \n",
      "1963  Operator: Greetings and welcome to the General...  \n",
      "2046  Operator: Good morning, and welcome to Procter...  \n",
      "2047  Operator: Good morning, and welcome to Procter...  \n",
      "\n",
      "[175 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_alls['date'] = pd.to_datetime(df_alls['date'])  # note: pd.to_datetime, not pd.to_date_time\n",
    "# df_alls[df_alls['date'].dt.year == 2024]\n",
    "\n",
    "df_filtered = df_alls[df_alls['date'] < pd.to_datetime('2024-02-23')]\n",
    "print(df_filtered) \n",
    "\n",
    "# print(df_alls[df_alls['year'] == 2025])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6732438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ticker  year quarter                date  \\\n",
      "3       APO  2024       4 2025-02-04 08:30:00   \n",
      "7       LII  2024       4 2025-01-29 09:30:00   \n",
      "15     WDAY  2025       4 2025-02-25 16:30:00   \n",
      "19      TPL  2024       4 2025-02-20 08:30:00   \n",
      "27     DELL  2025       4 2025-02-28 17:26:00   \n",
      "...     ...   ...     ...                 ...   \n",
      "2138     SO  2024       4 2025-02-20 13:00:00   \n",
      "2142   SPGI  2024       4 2025-02-11 08:30:00   \n",
      "2146    UNP  2024       4 2025-01-23 08:45:00   \n",
      "2150    XEL  2024       4 2025-02-06 10:00:00   \n",
      "2154    XOM  2024       4 2025-01-31 03:30:00   \n",
      "\n",
      "                                                content  \n",
      "3     Operator: Good morning, and welcome to Apollo ...  \n",
      "7     Operator: Welcome to the Lennox Fourth Quarter...  \n",
      "15    Operator: Welcome to Workday's Fourth Quarter ...  \n",
      "19    Operator: Greetings, and welcome to the Texas ...  \n",
      "27    Operator: Good afternoon and welcome to the Fi...  \n",
      "...                                                 ...  \n",
      "2138  Operator: Good afternoon. My name is Robert, a...  \n",
      "2142  Operator: Good morning, and welcome to S&P Glo...  \n",
      "2146  Operator: Greetings, welcome to Union Pacific'...  \n",
      "2150  Operator: Hello, and welcome to Xcel Energy 20...  \n",
      "2154  Jim Chapman: Good morning, everyone. Welcome t...  \n",
      "\n",
      "[474 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# df_2026['date'] = pd.to_datetime(df_2026['date'])\n",
    "\n",
    "# print(df_2026[(df_2026['date'].dt.year >= 2025) & (df_2026['date'].dt.month >= 3)])\n",
    "df_2026 = df_2026[df_2026['date'].dt.year >= 202]\n",
    "print(df_2026)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8234af51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0 ticker  year quarter                 date  \\\n",
      "0             0.0   DELL  2005       4  2006-01-26 11:39:13   \n",
      "1             1.0   DELL  2006       1  2006-04-20 12:46:09   \n",
      "2             2.0   DELL  2006       2  2006-07-14 12:00:43   \n",
      "3             3.0   DELL  2006       3  2006-10-17 13:18:26   \n",
      "4             4.0   DELL  2006       4  2007-01-23 12:15:14   \n",
      "...           ...    ...   ...     ...                  ...   \n",
      "31468         NaN     SO  2024       4  2025-02-20 13:00:00   \n",
      "31469         NaN   SPGI  2024       4  2025-02-11 08:30:00   \n",
      "31470         NaN    UNP  2024       4  2025-01-23 08:45:00   \n",
      "31471         NaN    XEL  2024       4  2025-02-06 10:00:00   \n",
      "31472         NaN    XOM  2024       4  2025-01-31 03:30:00   \n",
      "\n",
      "                                                 content  \n",
      "0      Executives: Tony Takazawa, Vice President of I...  \n",
      "1      Executives: Tony Takazawa, Vice President, Inv...  \n",
      "2      Executives: Joe Tucci - Chairman, President, C...  \n",
      "3      Executives: Joe Tucci - Chairman, President, C...  \n",
      "4      TRANSCRIPT SPONSOR :\\nExecutives: Tony Takazaw...  \n",
      "...                                                  ...  \n",
      "31468  Operator: Good afternoon. My name is Robert, a...  \n",
      "31469  Operator: Good morning, and welcome to S&P Glo...  \n",
      "31470  Operator: Greetings, welcome to Union Pacific'...  \n",
      "31471  Operator: Hello, and welcome to Xcel Energy 20...  \n",
      "31472  Jim Chapman: Good morning, everyone. Welcome t...  \n",
      "\n",
      "[31473 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# df_old['year'] = df_old['year'].astype(str)\n",
    "# df_old['quarter'] = df_old['quarter'].astype(str)\n",
    "# df_2026['year'] = df_2026['year'].astype(str)\n",
    "# df_2026['quarter'] = df_2026['quarter'].astype(str)\n",
    "\n",
    "# # Remove rows from df_old that match ticker/year/quarter in df_2026\n",
    "# df_old_filtered = df_old[~df_old.set_index(['ticker', 'year', 'quarter']).index.isin(\n",
    "#     df_2026.set_index(['ticker', 'year', 'quarter']).index\n",
    "# )]\n",
    "\n",
    "# # Concatenate df_old (filtered) with df_2026\n",
    "# merged_df = pd.concat([df_old_filtered, df_2026], ignore_index=True)\n",
    "\n",
    "# Result\n",
    "print(merged_df)\n",
    "\n",
    "merged_df = merged_df.to_csv(\"/Users/marcosmaldacena/Downloads/Thesis Data/transcripts_2006_2025_03_18.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd74d7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0 ticker  year  quarter                 date  \\\n",
      "0             0.0   DELL  2005        4  2006-01-26 11:39:13   \n",
      "1             1.0   DELL  2006        1  2006-04-20 12:46:09   \n",
      "2             2.0   DELL  2006        2  2006-07-14 12:00:43   \n",
      "3             3.0   DELL  2006        3  2006-10-17 13:18:26   \n",
      "4             4.0   DELL  2006        4  2007-01-23 12:15:14   \n",
      "...           ...    ...   ...      ...                  ...   \n",
      "30997         NaN    XEL  2023        4  2024-01-25 00:00:00   \n",
      "30998         NaN    XOM  2023        1  2023-04-28 09:51:04   \n",
      "30999         NaN    XOM  2023        2  2023-07-28 10:52:10   \n",
      "31000         NaN    XOM  2023        3  2023-10-27 11:40:16   \n",
      "31001         NaN    XOM  2023        4  2024-02-02 12:02:10   \n",
      "\n",
      "                                                 content  \n",
      "0      Executives: Tony Takazawa, Vice President of I...  \n",
      "1      Executives: Tony Takazawa, Vice President, Inv...  \n",
      "2      Executives: Joe Tucci - Chairman, President, C...  \n",
      "3      Executives: Joe Tucci - Chairman, President, C...  \n",
      "4      TRANSCRIPT SPONSOR :\\nExecutives: Tony Takazaw...  \n",
      "...                                                  ...  \n",
      "30997  Operator: Hello, and welcome to Xcel Energy 20...  \n",
      "30998  Operator: Good day, everyone, and welcome to t...  \n",
      "30999  Operator: Good day, everyone, and welcome to t...  \n",
      "31000  Operator: Good morning everyone and welcome to...  \n",
      "31001  Operator: Good morning, everyone, and welcome ...  \n",
      "\n",
      "[31002 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# file_path = \"/Users/marcosmaldacena/Downloads/Thesis Data/updated_2024_2025.csv\"\n",
    "# df_2026.to_csv(file_path)\n",
    "\n",
    "\n",
    "df_old = pd.read_csv(\"/Users/marcosmaldacena/Downloads/Thesis Data/transcripts_2006_2025.csv\")\n",
    "print(df_old)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8470fccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 ticker  year  quarter                 date  \\\n",
      "0           0   DELL  2005        4  2006-01-26 11:39:13   \n",
      "1           1   DELL  2006        1  2006-04-20 12:46:09   \n",
      "2           2   DELL  2006        2  2006-07-14 12:00:43   \n",
      "3           3   DELL  2006        3  2006-10-17 13:18:26   \n",
      "4           4   DELL  2006        4  2007-01-23 12:15:14   \n",
      "\n",
      "                                             content  \n",
      "0  Executives: Tony Takazawa, Vice President of I...  \n",
      "1  Executives: Tony Takazawa, Vice President, Inv...  \n",
      "2  Executives: Joe Tucci - Chairman, President, C...  \n",
      "3  Executives: Joe Tucci - Chairman, President, C...  \n",
      "4  TRANSCRIPT SPONSOR :\\nExecutives: Tony Takazaw...  \n",
      "0       2005\n",
      "1       2006\n",
      "2       2006\n",
      "3       2006\n",
      "4       2006\n",
      "        ... \n",
      "4394    2008\n",
      "4395    2009\n",
      "4396    2009\n",
      "4397    2009\n",
      "4398    2009\n",
      "Name: year, Length: 4399, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File path\n",
    "file_path = \"/Users/marcosmaldacena/Downloads/2005_2009.csv\"\n",
    "\n",
    "\n",
    "file_path_2 = \"/Users/marcosmaldacena/Downloads/2009_2013.csv\"\n",
    "\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())  # Shows the first 5 rows by default\n",
    "\n",
    "# Optionally, display all column names and the shape of the dataset\n",
    "print(df['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8388008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the combined DataFrame after removing duplicates by 'content':\n",
      "   Unnamed: 0 ticker  year  quarter                 date  \\\n",
      "0           0   DELL  2005        4  2006-01-26 11:39:13   \n",
      "1           1   DELL  2006        1  2006-04-20 12:46:09   \n",
      "2           2   DELL  2006        2  2006-07-14 12:00:43   \n",
      "3           3   DELL  2006        3  2006-10-17 13:18:26   \n",
      "4           4   DELL  2006        4  2007-01-23 12:15:14   \n",
      "\n",
      "                                             content  \n",
      "0  Executives: Tony Takazawa, Vice President of I...  \n",
      "1  Executives: Tony Takazawa, Vice President, Inv...  \n",
      "2  Executives: Joe Tucci - Chairman, President, C...  \n",
      "3  Executives: Joe Tucci - Chairman, President, C...  \n",
      "4  TRANSCRIPT SPONSOR :\\nExecutives: Tony Takazaw...  \n",
      "\n",
      "Shape of the combined DataFrame after removing duplicates by 'content': (10520, 6)\n",
      "\n",
      "Columns in the combined DataFrame:\n",
      "Index(['Unnamed: 0', 'ticker', 'year', 'quarter', 'date', 'content'], dtype='object')\n",
      "\n",
      "Summary Statistics:\n",
      "         Unnamed: 0          year       quarter\n",
      "count  10520.000000  10520.000000  10520.000000\n",
      "mean    3160.687262   2010.145057      2.572909\n",
      "std     2068.115831      2.116141      1.119620\n",
      "min        0.000000   2005.000000      1.000000\n",
      "25%     1439.750000   2008.000000      2.000000\n",
      "50%     2924.500000   2010.000000      3.000000\n",
      "75%     4435.250000   2012.000000      4.000000\n",
      "max     7710.000000   2013.000000      4.000000\n",
      "\n",
      "Year-wise counts:\n",
      "year\n",
      "2013    1797\n",
      "2012    1746\n",
      "2008    1573\n",
      "2011    1503\n",
      "2009    1406\n",
      "2010    1218\n",
      "2007     868\n",
      "2006     341\n",
      "2005      68\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "file_path_1 = \"/Users/marcosmaldacena/Downloads/2005_2009.csv\"\n",
    "file_path_2 = \"/Users/marcosmaldacena/Downloads/2009_2013.csv\"\n",
    "\n",
    "# Load the CSV files into DataFrames\n",
    "df1 = pd.read_csv(file_path_1)\n",
    "df2 = pd.read_csv(file_path_2)\n",
    "\n",
    "# Combine the two DataFrames\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Remove duplicates based on the 'content' column\n",
    "if 'content' in combined_df.columns:\n",
    "    combined_df = combined_df.drop_duplicates(subset=['content'])\n",
    "else:\n",
    "    print(\"The 'content' column is not found in the dataset. No duplicates removed based on 'content'.\")\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(\"First few rows of the combined DataFrame after removing duplicates by 'content':\")\n",
    "print(combined_df.head())\n",
    "\n",
    "# Display the shape of the combined DataFrame\n",
    "print(\"\\nShape of the combined DataFrame after removing duplicates by 'content':\", combined_df.shape)\n",
    "\n",
    "# Display column names\n",
    "print(\"\\nColumns in the combined DataFrame:\")\n",
    "print(combined_df.columns)\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(combined_df.describe())\n",
    "\n",
    "# Display unique years and their counts\n",
    "if 'year' in combined_df.columns:\n",
    "    print(\"\\nYear-wise counts:\")\n",
    "    print(combined_df['year'].value_counts())\n",
    "else:\n",
    "    print(\"\\nThe 'year' column is not present in the dataset.\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c3c9c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the final DataFrame:\n",
      "   Unnamed: 0 ticker  year  quarter                 date  \\\n",
      "0         0.0   DELL  2005        4  2006-01-26 11:39:13   \n",
      "1         1.0   DELL  2006        1  2006-04-20 12:46:09   \n",
      "2         2.0   DELL  2006        2  2006-07-14 12:00:43   \n",
      "3         3.0   DELL  2006        3  2006-10-17 13:18:26   \n",
      "4         4.0   DELL  2006        4  2007-01-23 12:15:14   \n",
      "\n",
      "                                             content  \n",
      "0  Executives: Tony Takazawa, Vice President of I...  \n",
      "1  Executives: Tony Takazawa, Vice President, Inv...  \n",
      "2  Executives: Joe Tucci - Chairman, President, C...  \n",
      "3  Executives: Joe Tucci - Chairman, President, C...  \n",
      "4  TRANSCRIPT SPONSOR :\\nExecutives: Tony Takazaw...  \n",
      "\n",
      "Shape of the final DataFrame: (31002, 6)\n",
      "\n",
      "Summary Statistics:\n",
      "         Unnamed: 0          year       quarter\n",
      "count  10520.000000  31002.000000  31002.000000\n",
      "mean    3160.687262   2015.996226      2.503032\n",
      "std     2068.115831      5.053530      1.114088\n",
      "min        0.000000   2005.000000      1.000000\n",
      "25%     1439.750000   2012.000000      2.000000\n",
      "50%     2924.500000   2016.000000      3.000000\n",
      "75%     4435.250000   2020.000000      3.000000\n",
      "max     7710.000000   2025.000000      4.000000\n",
      "\n",
      "Year-wise counts:\n",
      "year\n",
      "2023    1953\n",
      "2022    1943\n",
      "2021    1933\n",
      "2020    1930\n",
      "2019    1903\n",
      "2018    1882\n",
      "2017    1863\n",
      "2016    1844\n",
      "2015    1827\n",
      "2014    1805\n",
      "2013    1797\n",
      "2012    1746\n",
      "2008    1573\n",
      "2024    1527\n",
      "2011    1503\n",
      "2009    1406\n",
      "2010    1218\n",
      "2007     868\n",
      "2006     341\n",
      "2025      72\n",
      "2005      68\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "file_path_1 = \"/Users/marcosmaldacena/Downloads/2005_2009.csv\"\n",
    "file_path_2 = \"/Users/marcosmaldacena/Downloads/2009_2013.csv\"\n",
    "file_path_merged = \"/Users/marcosmaldacena/Downloads/Thesis Data/merged_earnings_call_transcripts.csv\"\n",
    "output_path = \"/Users/marcosmaldacena/Downloads/Thesis Data/transcripts_2006_2025.csv\"\n",
    "\n",
    "# Load the first two CSV files\n",
    "df1 = pd.read_csv(file_path_1)\n",
    "df2 = pd.read_csv(file_path_2)\n",
    "\n",
    "# Combine the first two DataFrames\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Remove duplicates based on the 'content' column\n",
    "if 'content' in combined_df.columns:\n",
    "    combined_df = combined_df.drop_duplicates(subset=['content'])\n",
    "else:\n",
    "    print(\"The 'content' column is not found in the dataset. No duplicates removed based on 'content'.\")\n",
    "\n",
    "# Load the merged DataFrame\n",
    "df_merged = pd.read_csv(file_path_merged)\n",
    "\n",
    "# Merge the combined DataFrame with the merged DataFrame\n",
    "final_df = pd.concat([combined_df, df_merged], ignore_index=True)\n",
    "\n",
    "# Remove duplicates from the final DataFrame based on the 'content' column\n",
    "if 'content' in final_df.columns:\n",
    "    final_df = final_df.drop_duplicates(subset=['content'])\n",
    "else:\n",
    "    print(\"The 'content' column is not found in the final dataset. No duplicates removed based on 'content'.\")\n",
    "\n",
    "# Save the resulting DataFrame to a new CSV file\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the first few rows of the saved DataFrame\n",
    "print(\"First few rows of the final DataFrame:\")\n",
    "print(final_df.head())\n",
    "\n",
    "# Display the shape of the final DataFrame\n",
    "print(\"\\nShape of the final DataFrame:\", final_df.shape)\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(final_df.describe())\n",
    "\n",
    "# Display unique years and their counts\n",
    "if 'year' in final_df.columns:\n",
    "    print(\"\\nYear-wise counts:\")\n",
    "    print(final_df['year'].value_counts())\n",
    "else:\n",
    "    print(\"\\nThe 'year' column is not present in the final dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a752f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013 = pd.read_csv(\"/Users/marcosmaldacena/Downloads/Thesis Data/Earnings Calls/sp500_earnings_transcripts.csv\")\n",
    "df_2014 = pd.read_csv(\"/Users/marcosmaldacena/Downloads/Thesis Data/2014_earnings_call_transcripts.csv\")\n",
    "df_2015_2016 = pd.read_csv(\"/Users/marcosmaldacena/Downloads/Thesis Data/2015_2016_earnings_call_transcripts.csv\")\n",
    "df_others = pd.read_csv(\"/Users/marcosmaldacena/Downloads/Thesis Data/other_years_earnings_call_transcripts.csv\")\n",
    "df_2023 = pd.read_csv(\"/Users/marcosmaldacena/Downloads/Thesis Data/Earnings Calls/sp500_earnings_transcripts_2023.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d0e2443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ticker  year  quarter                 date  \\\n",
      "0      DELL  2023        1  2022-05-26 21:37:11   \n",
      "1      DELL  2023        2  2022-08-25 23:12:03   \n",
      "2      DELL  2023        3  2022-11-21 19:34:06   \n",
      "3      DELL  2023        4  2023-03-02 20:44:03   \n",
      "4      ERIE  2023        1  2023-04-28 14:44:15   \n",
      "...     ...   ...      ...                  ...   \n",
      "1961    XEL  2023        4  2024-01-25 00:00:00   \n",
      "1962    XOM  2023        1  2023-04-28 09:51:04   \n",
      "1963    XOM  2023        2  2023-07-28 10:52:10   \n",
      "1964    XOM  2023        3  2023-10-27 11:40:16   \n",
      "1965    XOM  2023        4  2024-02-02 12:02:10   \n",
      "\n",
      "                                                content  \n",
      "0     Operator: Good afternoon, and welcome to the F...  \n",
      "1     Operator: Please stand by. Good afternoon. And...  \n",
      "2     Operator: Good afternoon, ladies and gentlemen...  \n",
      "3     Operator: Good afternoon, and welcome to the F...  \n",
      "4     Operator: Good morning, and welcome to the Eri...  \n",
      "...                                                 ...  \n",
      "1961  Operator: Hello, and welcome to Xcel Energy 20...  \n",
      "1962  Operator: Good day, everyone, and welcome to t...  \n",
      "1963  Operator: Good day, everyone, and welcome to t...  \n",
      "1964  Operator: Good morning everyone and welcome to...  \n",
      "1965  Operator: Good morning, everyone, and welcome ...  \n",
      "\n",
      "[1966 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d353f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "\u001b[1m\u001b[97m| Model Descriptor                        | Hugging Face Repo                                   | Context Length |\u001b[0m\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.1-8B                             | meta-llama/Llama-3.1-8B                             | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.1-70B                            | meta-llama/Llama-3.1-70B                            | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.1-405B:bf16-mp8                  | meta-llama/Llama-3.1-405B                           | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.1-405B                           | meta-llama/Llama-3.1-405B-FP8                       | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.1-405B:bf16-mp16                 | meta-llama/Llama-3.1-405B                           | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.1-8B-Instruct                    | meta-llama/Llama-3.1-8B-Instruct                    | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.1-70B-Instruct                   | meta-llama/Llama-3.1-70B-Instruct                   | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.1-405B-Instruct:bf16-mp8         | meta-llama/Llama-3.1-405B-Instruct                  | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.1-405B-Instruct                  | meta-llama/Llama-3.1-405B-Instruct-FP8              | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.1-405B-Instruct:bf16-mp16        | meta-llama/Llama-3.1-405B-Instruct                  | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.2-1B                             | meta-llama/Llama-3.2-1B                             | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.2-3B                             | meta-llama/Llama-3.2-3B                             | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.2-11B-Vision                     | meta-llama/Llama-3.2-11B-Vision                     | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.2-90B-Vision                     | meta-llama/Llama-3.2-90B-Vision                     | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.2-1B-Instruct                    | meta-llama/Llama-3.2-1B-Instruct                    | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.2-3B-Instruct                    | meta-llama/Llama-3.2-3B-Instruct                    | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.2-1B-Instruct:int4-qlora-eo8     | meta-llama/Llama-3.2-1B-Instruct-QLORA_INT4_EO8     | 8K             |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.2-1B-Instruct:int4-spinquant-eo8 | meta-llama/Llama-3.2-1B-Instruct-SpinQuant_INT4_EO8 | 8K             |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.2-3B-Instruct:int4-qlora-eo8     | meta-llama/Llama-3.2-3B-Instruct-QLORA_INT4_EO8     | 8K             |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.2-3B-Instruct:int4-spinquant-eo8 | meta-llama/Llama-3.2-3B-Instruct-SpinQuant_INT4_EO8 | 8K             |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.2-11B-Vision-Instruct            | meta-llama/Llama-3.2-11B-Vision-Instruct            | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama3.2-90B-Vision-Instruct            | meta-llama/Llama-3.2-90B-Vision-Instruct            | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama-Guard-3-11B-Vision                | meta-llama/Llama-Guard-3-11B-Vision                 | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama-Guard-3-1B:int4                   | meta-llama/Llama-Guard-3-1B-INT4                    | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama-Guard-3-1B                        | meta-llama/Llama-Guard-3-1B                         | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama-Guard-3-8B                        | meta-llama/Llama-Guard-3-8B                         | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama-Guard-3-8B:int8                   | meta-llama/Llama-Guard-3-8B-INT8                    | 128K           |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n",
      "| Llama-Guard-2-8B                        | meta-llama/Llama-Guard-2-8B                         | 4K             |\r\n",
      "+-----------------------------------------+-----------------------------------------------------+----------------+\r\n"
     ]
    }
   ],
   "source": [
    "!llama model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b90d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "!llama model download --source meta --model-id Llama3.1-70B-Instruct --url \"https://llama3-1.llamameta.net/*?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiMWdnbmRodTVuMno2bzhjNXUzbWdqdWZvIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvbGxhbWEzLTEubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTMzODg0N319fV19&Signature=rY2tZefAQ7GxLjm5nc4koK7EQ4H48j-anoWyr7r33FKTTVcGrY2MdyAZhfPceMbPrNAtekYwTExWIrDk67ug1YpQUXWoFJU9-ojBWi0TVVn-8ye4%7EIqTZhjfnbkFdMw38tjGM1EBLdcueNt46dYJoDokyp%7EE%7EWxum7nU4cw4q1KE9ShuY0Yrh5uMVR5GEKHpVhHP4J8lksBb%7ErBDA0j5Kc7zt2KaGgd-RbS-H%7EtPPpNy%7ElFnFlNgY0-UXYBt8IuCvc2jQggy1JGyN%7Egt4QxUk8Xl5paceiYJBmsqt6XCAswlqCCI4Ls6LVGxdvEV3TkBTc0cYSdiM%7EzZVjQ53YEUrg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1242721713647035\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f692b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://llama3-1.llamameta.net/*?Policy=eyJTdGF0ZW1lbnQiOiI7InVuaXF1ZV9oYXNoIjoibmRodTVuMno2bzhjNXUzbWdqdWZvIiwidHRwczovLmxsYW1hLm1ldGEubmV0Ly...&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1242721'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"https://llama3-1.llamameta.net/*?Policy=eyJTdGF0ZW1lbnQiOiI7InVuaXF1ZV9oYXNoIjoibmRodTVuMno2bzhjNXUzbWdqdWZvIiwidHRwczovLmxsYW1hLm1ldGEubmV0Ly...&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1242721\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
